/*
 * Copyright 2010 Keith Stevens
 *
 * This file is part of the S-Space package and is covered under the terms and
 * conditions therein.
 *
 * The S-Space package is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License version 2 as published
 * by the Free Software Foundation and distributed hereunder to you.
 *
 * THIS SOFTWARE IS PROVIDED "AS IS" AND NO REPRESENTATIONS OR WARRANTIES,
 * EXPRESS OR IMPLIED ARE MADE.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, WE MAKE
 * NO REPRESENTATIONS OR WARRANTIES OF MERCHANT- ABILITY OR FITNESS FOR ANY
 * PARTICULAR PURPOSE OR THAT THE USE OF THE LICENSED SOFTWARE OR DOCUMENTATION
 * WILL NOT INFRINGE ANY THIRD PARTY PATENTS, COPYRIGHTS, TRADEMARKS OR OTHER
 * RIGHTS.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program. If not, see <http://www.gnu.org/licenses/>.
 */

package edu.ucla.sspace.dependency;

import edu.ucla.sspace.text.IteratorFactory;
import edu.ucla.sspace.text.Stemmer;
import edu.ucla.sspace.text.TokenFilter;

import edu.ucla.sspace.util.Duple;
import edu.ucla.sspace.util.MultiMap;
import edu.ucla.sspace.util.HashMultiMap;

import java.io.BufferedReader;
import java.io.IOError;
import java.io.IOException;

import java.util.ArrayList;
import java.util.Collection;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.NavigableMap;
import java.util.TreeMap;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;

import org.w3c.dom.Element;
import org.w3c.dom.Document;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;


/**
 * A class for extracting dependency parsed sentences from <a
 * href="http://wacky.sslmit.unibo.it/doku.php?id=corpora">WaCKy</a> corpora.
 * These corpora use a modified <a
 * href="http://nextens.uvt.nl/depparse-wiki/DataFormat">CoNLL format</a>, which
 * are generated by the <a href="http://maltparser.org/index.html">Malt
 * Parser</a>.  The ordering of the CoNLL format can be specified with an xml
 * file following the format specified <a
 * href="http://maltparser.org/userguide.html#inout">here</a>.
 *
 * </p>
 *
 * Parsed sentences are returned as an array of {@link DependencyTreeNode}
 * innstances.  The nodes contain relations between each word in the sentence.
 * The nodes in the returned array are ordered by the ordering of word
 * occurrences.
 *
 * </p>
 *
 * This class optionally supports filtering sentences to remove words.  The
 * nodes for those removed words will still remain in the parse tree.
 * Similarly, the relations connecting the removed words will also existing.
 * However, the {@link DependencyTreeNode#word()} method will return {@link
 * IteratorFactory#EMPTY_TOKEN} to indicate that the node's text was filtered
 * out.  Note that the node will still have the original part of speech.
 *
 * @author David Jurgens
 */
public class WaCKyDependencyExtractor implements DependencyExtractor {

    /**
     * A {@link TokenFilter} that will accept or reject tokens before they are
     * stored in a {@link DependencyTreeNode}, if provided.
     */
    private final TokenFilter filter;

    /**
     * A {@link Stemmer} that will lemmatize tokens before they are stored in a
     * {@link DependencyTreeNode}, if provided.
     */
    private final Stemmer stemmer;

    /**
     * The feature index for the node id.
     */
    private final int idIndex;

    /**
     * The feature index for the word's form.
     */
    private final int formIndex;

    /**
     * The feature index for the word's lemma.
     */
    private final int lemmaIndex;

    /**
     * The feature index for the word's part of speech tag.
     */
    private final int posIndex;

    /**
     * The feature index for the parent, or head, of the current node.
     */
    private final int parentIndex;

    /**
     * The feature index for the relation to the parent, or head, of the current
     * node.
     */
    private final int relationIndex;

    /**
     * Creates a new {@link WaCKyDependencyExtractor} that assumes the default
     * ordering for {@code Malt} dependency parses.
     */
    public WaCKyDependencyExtractor() {
        this(null,null);
    }

    /**
     * Creates a new {@link WaCKyDependencyExtractor} that assumes the default
     * ordering for {@code Malt} dependency parses and uses the given {@link
     * TokenFilter} and {@link Stemmer}.
     */
    public WaCKyDependencyExtractor(TokenFilter filter, Stemmer stemmer) {
        this.filter = filter;
        this.stemmer = stemmer;

        idIndex = 3;
        formIndex = 0;
        lemmaIndex = 1;
        posIndex = 2;
        parentIndex = 4;
        relationIndex = 5;
    }
       
    /**
     * Extracts a dependency parse tree from the provided reader.  The tree is
     * assumed to be in the CoNLL format used by WaCKy.
     *
     * </p>
     *
     * The CoNNLL features that are of interest are ID, LEMMA or FORM, POSTAG,
     * HEAD, and DEPREL which are the id of the node, the string for the word at
     * this position, the part of speech tag, the parent of this node, and the
     * relation to the parent, respectively.  These features will be extracted
     * and returned as an array based tree structure ordered by the occurrence
     * of the words in the sentence.
     *
     * @param reader a reader containing one or more parse trees in the CoNLL
     *        format used by WaCKy
     *
     * @return an array of {@link DependencyTreeNode}s that compose a dependency
     *         tree, or {@code null} if no tree is present in the reader.
     *
     * @throws IOException when errors are encountered during reading
     */
    public DependencyTreeNode[] readNextTree(BufferedReader reader) 
            throws IOException {

        List<SimpleDependencyTreeNode> nodes =
            new ArrayList<SimpleDependencyTreeNode>();

        // When building the tree, keep track of all the relations seen between
        // the nodes.  The nodes need to be linked by DependencyRelations, which
        // need DependencyTreeNode instances.  However, during parsing, we may
        // encounter a forward reference to a Node not yet created, so the map
        // ensures that the relation will still be added.
        MultiMap<Integer,Duple<Integer,String>> relationsToAdd 
            = new HashMultiMap<Integer,Duple<Integer,String>>();

        StringBuilder sb = new StringBuilder();

        // Read each line in the document to extract the feature set for each
        // word in the sentence.
        int id = 0;
        for (String line = null; ((line = reader.readLine()) != null); ) {
            // If a new line is encountered and no lines have been handled yet,
            // skip all new lines.
            if (line.length() == 0 && nodes.size() == 0)
                continue;

            // If a new line is encountered and lines have already been
            // processed, we have finished processing the entire sentence and
            // can stop.
            if (line.length() == 0)
                break;

            sb.append(line).append("\n");

            // CoNLL formats using tabs between features.
            String[] nodeFeatures = line.split("\\s+");

            int parent = 0;
            String word, pos, rel;
            word = pos = rel = null;

            try {
                // Get the node id and the parent node id.
                parent = Integer.parseInt(nodeFeatures[parentIndex]) - 1;
                
                word = getWord(nodeFeatures);
                
                // Get the part of speech of the node.
                pos = nodeFeatures[posIndex];
                
                // Get the relation between this node and it's head node.
                rel = nodeFeatures[relationIndex].toLowerCase();
            } catch (Exception e) {
                System.out.println("offending line: " + line);
                e.printStackTrace();
            }

            // Create the new relation.
            SimpleDependencyTreeNode curNode = 
                new SimpleDependencyTreeNode(word, pos);

            // Set the dependency link between this node and it's parent node.
            // If the parent is negative then the node itself is a root node and
            // has no parent.
            if (parent > 0) {
                // Add to the list so we'll fill in this link once the tree is
                // has been fully seen and any noun phrase nodes merged
                relationsToAdd.put(id,
                        new Duple<Integer,String>(parent, rel));
            }
            
            // Finally, add the current node to the
            nodes.add(curNode);
            id++;
        }

        if (nodes.size() == 0)
            return null;

        // Keep track of any nodes that might need to be removed due to being
        // merged into a single noun phrase nodes.
        NavigableMap<Integer,Integer> remappedNodes = 
            new TreeMap<Integer,Integer>();
        
    
        // Merge all of the noun phrase nodes into a single node.  This
        // effectively creates a single node with "United States of America" as
        // the text, rather than four nodes.
        for (int i = 0; i < nodes.size(); ++i) {
            SimpleDependencyTreeNode n = nodes.get(i);
            String pos = n.pos();
            if (!(pos.equals("NP") || pos.equals("NPS")))
                continue;

            // See if there are more nodes that are either noun phrase nodes, or
            // are nodes with parts of speech that could fall between a noun
            // phranse, e.g. "of", " 's"
            int nounPhraseNodes = 0;
            for (int j = i+1; j < nodes.size(); ++j) {
                pos = nodes.get(j).pos();
                if (pos.equals("NP") || pos.equals("NPS")) {
                    nounPhraseNodes = j - i;
                }
                // Words such as "of" or "to" might be a part of the noun
                // phrase, but don't include them in the total length of a noun
                // phrase, i.e. only a noun phrase POS can end the phrase.
                else if (pos.equals("IN") || pos.equals("TO"))
                    continue;
                // If the word wasn't a noun phrase or a connection, just stop
                // the processing.
                else
                    break;
                
            }
            
            // If we found more nodes to group into a single noun phrase, then
            // rewrite all the links to them to the current node
            if (nounPhraseNodes > 0) {
                for (int k = i + 1; k <= i + nounPhraseNodes; ++k)
                    remappedNodes.put(k, i);

                // Add all the text from the other noun phrase nodes into the
                // current node's text
                StringBuilder nounPhrase = 
                    new StringBuilder((nounPhraseNodes + 1) * 8);
                for (int k = i; k < i + nounPhraseNodes + 1; ++k) {
                    nounPhrase.append(nodes.get(k).word());
                    if (k < i + nounPhraseNodes)
                        nounPhrase.append(' ');
                }
                n.setWord(nounPhrase.toString());
                // Update the i index to skip over the nodes that were merged.
                // This avoids creating subsets of the noun phrase.
                i += nounPhraseNodes;
            }
        }
        
        if (relationsToAdd.size() > 0) {
            // Process all the child links that were not handled during the
            // processing of the words.
            for (Map.Entry<Integer,Duple<Integer,String>> parentAndRel :
                     relationsToAdd.entrySet()) {

                //  Each of the nodes may have been remapped during the noun
                //  phrase chunking, so check whether the index has been
                //  updated.
                Integer parent = parentAndRel.getKey();
                Duple<Integer,String> d = parentAndRel.getValue();
                Integer i = remappedNodes.get(parent);
                if (i != null)
                    parent = i;

                Integer headIndex = d.x;
                i = remappedNodes.get(headIndex);
                if (i != null)
                    headIndex = i;

                // In addition, ensure that after the remapping, the node isn't
                // linking to itself
                if (parent.equals(headIndex))
                    continue;

                SimpleDependencyTreeNode dep = nodes.get(parent);
                SimpleDependencyTreeNode head = nodes.get(headIndex);
                DependencyRelation r = new SimpleDependencyRelation(
                    head, d.y, dep);
                head.addNeighbor(r);
                dep.addNeighbor(r);                
            }
        }

        // Once all the relations have been added remove any of the dangling
        // nodes that were merged into a single noun phrase node.  Remove in
        // reverse order to ensure that removing by index doesn't affect the
        // subsequent indices.
        for (Integer i : remappedNodes.descendingKeySet())
            nodes.remove(i);

        return nodes.toArray(
                new SimpleDependencyTreeNode[nodes.size()]);
    }

    /**
     * Returns a string representation of the word for a given node in the
     * dependency parse tree.  First, the original word is filtered and if the
     * word is not accepted, the empty string is returned.  Accepted words will
     * then be stemmed if either a lemma is provided by the parser or a {@link
     * Stemmer} is provided with a preference given to the parser provided
     * lemma.  If neither case holds, the original term is returned.
     */
    private String getWord(String[] nodeFeatures) {
        String word = nodeFeatures[formIndex].toLowerCase();
        // Filter if neccessary.
        if (filter != null && !filter.accept(word))
            return IteratorFactory.EMPTY_TOKEN;
        // Get the lemma and check it's value.  Stem if needed.
        String lemma = nodeFeatures[lemmaIndex];
        if (lemma.equals("_"))
            return (stemmer == null) ? word : stemmer.stem(word);
        return lemma;
    }
}
